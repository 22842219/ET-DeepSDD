{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "How to play our model on Google Colab?_by Ziyu Zhao.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1UZM298HJLt84x1-M9umTdmiDO9kYpNnl",
      "authorship_tag": "ABX9TyNNrJ8U5prMoapGtzN8P+qT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/22842219/ET-DeepSDD/blob/main/How_to_play_our_model_on_Google_Colab%3F_by_ZZY.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2phuUlrjLB2"
      },
      "source": [
        "## How to run our experiments?\n",
        "Firstly, git clone our repository to your google drive and choose runtime \"GPU\".  \n",
        "\n",
        "Secondly, open file \"config.json\" to config the experiment.  \n",
        "\n",
        "Then, run our experiments as the following tutorial."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z60FFtugY0Qb",
        "outputId": "c6705a00-9f40-4959-a4b8-bb3553e4514a"
      },
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path = \"/content/drive/MyDrive/ET-DeepSDD\"\n",
        "os.chdir(path)\n",
        "os.listdir(path)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['nfgec_evaluate.py',\n",
              " 'progress_bar.py',\n",
              " 'logger.py',\n",
              " 'README.md',\n",
              " 'load_config.py',\n",
              " 'train.py',\n",
              " 'evaluate.py',\n",
              " 'data',\n",
              " '__pycache__',\n",
              " 'bert',\n",
              " '.git',\n",
              " 'runs',\n",
              " 'models',\n",
              " 'cased_L-12_H-768_A-12',\n",
              " 'Reasoning_process_explanation_by_ZZY.ipynb',\n",
              " 'build_data.py',\n",
              " 'data_utils.py',\n",
              " 'config.json',\n",
              " 'model.py',\n",
              " 'cased_L-12_H-768_A-12.zip',\n",
              " 'out.file',\n",
              " 'cased_L-12_H-768_A-12.zip.1']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sE7FCQHZMxWF",
        "outputId": "39f8dd34-96a7-4c33-8d6d-431c9d18a324",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from pathlib import Path\n",
        "here = Path(path)\n",
        "print(here)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/ET-DeepSDD\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82t2tReVHntm"
      },
      "source": [
        "import sys, os, re\n",
        "import json\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Creates the data distribution of each sample rate from the raw whole dataset. \n",
        "In order to have the fair enough comparision and the test if our model is sensitive with the volume of dataset or not,\n",
        "we use the same validation and test datsets.\n",
        "The sample rate considered: [0.1:0.9].\n",
        "\"\"\"\n",
        "\n",
        "sample_ratio = [0.2, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
        "infile = r\"data/datasets/bbn_modified\"\n",
        "# infile = '{}/{}'.format(basefile, dataset)\n",
        "for file in os.listdir(infile):\n",
        "  filepath = '{}/{}'.format(infile,file)\n",
        "  with open(filepath) as f:\n",
        "    records = [json.loads(x) for x in f]\n",
        "\n",
        "  count = len(records)\n",
        "  print(\"count:\", count)\n",
        "\n",
        "  for r in sample_ratio:\n",
        "    folder = '_{}/'.format(r)\n",
        "    folderpath = infile + folder\n",
        "    # print(\"filepath:\", filepath)\n",
        "\n",
        "    if not os.path.exists(os.path.dirname(folderpath)):\n",
        "      try:\n",
        "        os.makedirs(os.path.dirname(folderpath))\n",
        "      except OSError as exc:\n",
        "        if exc.errno != errno.EEXITST:\n",
        "          raise\n",
        "\n",
        "    if file == \"train.json\":\n",
        "      sample_count = math.ceil(count * r)\n",
        "    else:\n",
        "      sample_count = count\n",
        "    sample_indexes = np.random.choice(\n",
        "      count,\n",
        "      sample_count)\n",
        "\n",
        "    sample_records = []\n",
        "    for sample_index in sample_indexes:\n",
        "      sample_record = records[sample_index]\n",
        "      sample_records.append(sample_record)\n",
        "\n",
        "    assert len(sample_records) == sample_count\n",
        "    print(folderpath)\n",
        "\n",
        "    with open(here / folderpath/file,\"a\") as f:\n",
        "      for record in sample_records:\n",
        "        f.write(json.dumps(record) + \"\\n\")\n",
        "    print(\"Sampled {} records from {} original modified records.\".format( sample_count, count))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ejr40061XQIC",
        "outputId": "3d341a80-de72-476c-a087-d1f9323a7344"
      },
      "source": [
        "!pip install colorama\n",
        "!pip install jsonlines\n",
        "!pip install pysdd\n",
        "!pip install PySDD\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Installing collected packages: colorama\n",
            "Successfully installed colorama-0.4.4\n",
            "Collecting jsonlines\n",
            "  Downloading https://files.pythonhosted.org/packages/d4/58/06f430ff7607a2929f80f07bfd820acbc508a4e977542fefcc522cde9dff/jsonlines-2.0.0-py3-none-any.whl\n",
            "Installing collected packages: jsonlines\n",
            "Successfully installed jsonlines-2.0.0\n",
            "Collecting pysdd\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9a/5d/0bc570dda1dec89de5c1b7954aede5e0690fd9baee282ce20a27cf69f700/PySDD-0.2.10.tar.gz (3.5MB)\n",
            "\u001b[K     |████████████████████████████████| 3.5MB 6.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: cython>=0.29.6 in /usr/local/lib/python3.7/dist-packages (from pysdd) (0.29.22)\n",
            "Building wheels for collected packages: pysdd\n",
            "  Building wheel for pysdd (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pysdd: filename=PySDD-0.2.10-cp37-cp37m-linux_x86_64.whl size=2321861 sha256=c60fa9332fe6758509a6cc05b500ef55a8cc0d3b65231c3be33525d7a8ca6caa\n",
            "  Stored in directory: /root/.cache/pip/wheels/2e/b6/9a/1c7f59c5dee1eb2bd9d606d26b39ee8b9473ceb568fc91d54d\n",
            "Successfully built pysdd\n",
            "Installing collected packages: pysdd\n",
            "Successfully installed pysdd-0.2.10\n",
            "Requirement already satisfied: PySDD in /usr/local/lib/python3.7/dist-packages (0.2.10)\n",
            "Requirement already satisfied: cython>=0.29.6 in /usr/local/lib/python3.7/dist-packages (from PySDD) (0.29.22)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAvVDGT-hfBm"
      },
      "source": [
        "## Download and activate bert"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gu6VL1l1ebnb",
        "outputId": "7cba44f5-85c3-4a51-9b2c-0e292b0d7a38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install bert-serving-client\n",
        "!pip install -U bert-serving-server[http]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-serving-client\n",
            "  Downloading https://files.pythonhosted.org/packages/1f/09/aae1405378a848b2e87769ad89a43d6d71978c4e15534ca48e82e723a72f/bert_serving_client-1.10.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from bert-serving-client) (1.19.5)\n",
            "Requirement already satisfied: pyzmq>=17.1.0 in /usr/local/lib/python3.7/dist-packages (from bert-serving-client) (22.0.3)\n",
            "Installing collected packages: bert-serving-client\n",
            "Successfully installed bert-serving-client-1.10.0\n",
            "Collecting bert-serving-server[http]\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/bd/cab677bbd0c5fb08b72e468371d2bca6ed9507785739b4656b0b5470d90b/bert_serving_server-1.10.0-py3-none-any.whl (61kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 3.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from bert-serving-server[http]) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from bert-serving-server[http]) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from bert-serving-server[http]) (1.15.0)\n",
            "Collecting GPUtil>=1.3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: pyzmq>=17.1.0 in /usr/local/lib/python3.7/dist-packages (from bert-serving-server[http]) (22.0.3)\n",
            "Collecting flask-cors; extra == \"http\"\n",
            "  Downloading https://files.pythonhosted.org/packages/db/84/901e700de86604b1c4ef4b57110d4e947c218b9997adf5d38fa7da493bce/Flask_Cors-3.0.10-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: bert-serving-client; extra == \"http\" in /usr/local/lib/python3.7/dist-packages (from bert-serving-server[http]) (1.10.0)\n",
            "Requirement already satisfied, skipping upgrade: flask; extra == \"http\" in /usr/local/lib/python3.7/dist-packages (from bert-serving-server[http]) (1.1.2)\n",
            "Collecting flask-compress; extra == \"http\"\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/d5/69b13600230d24310b98a52da561113fc01a5c17acf77152761eef3e50f1/Flask_Compress-1.9.0-py3-none-any.whl\n",
            "Collecting flask-json; extra == \"http\"\n",
            "  Downloading https://files.pythonhosted.org/packages/6f/2d/4c21d98b11f3a206fabbdd965b53a2ca3ee9fab7646c93cf36c060e8f1a4/Flask_JSON-0.3.4-py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: itsdangerous>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask; extra == \"http\"->bert-serving-server[http]) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: click>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask; extra == \"http\"->bert-serving-server[http]) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: Werkzeug>=0.15 in /usr/local/lib/python3.7/dist-packages (from flask; extra == \"http\"->bert-serving-server[http]) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: Jinja2>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask; extra == \"http\"->bert-serving-server[http]) (2.11.3)\n",
            "Collecting brotli\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/ea/5bd575511b37bbd1c794606a0a621e6feff8e96b7dd007a86a5d218b2d94/Brotli-1.0.9-cp37-cp37m-manylinux1_x86_64.whl (357kB)\n",
            "\u001b[K     |████████████████████████████████| 358kB 7.2MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.10.1->flask; extra == \"http\"->bert-serving-server[http]) (1.1.1)\n",
            "Building wheels for collected packages: GPUtil\n",
            "  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPUtil: filename=GPUtil-1.4.0-cp37-none-any.whl size=7411 sha256=f065030d7493987eb5f55bd97a899e3840c24f3962faa9b03dfa49f0fea24885\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built GPUtil\n",
            "Installing collected packages: GPUtil, flask-cors, brotli, flask-compress, flask-json, bert-serving-server\n",
            "Successfully installed GPUtil-1.4.0 bert-serving-server-1.10.0 brotli-1.0.9 flask-compress-1.9.0 flask-cors-3.0.10 flask-json-0.3.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EA8GMMOtfjk7",
        "outputId": "dae9a0dc-ccfe-46e3-e015-3cfd5eec5bb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget https://storage.googleapis.com/bert_models/2018_10_18/cased_L-12_H-768_A-12.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-03-25 04:25:45--  https://storage.googleapis.com/bert_models/2018_10_18/cased_L-12_H-768_A-12.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 173.194.196.128, 64.233.191.128, 142.250.125.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|173.194.196.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 404261442 (386M) [application/zip]\n",
            "Saving to: ‘cased_L-12_H-768_A-12.zip.1’\n",
            "\n",
            "cased_L-12_H-768_A- 100%[===================>] 385.53M  61.1MB/s    in 6.5s    \n",
            "\n",
            "2021-03-25 04:25:52 (59.8 MB/s) - ‘cased_L-12_H-768_A-12.zip.1’ saved [404261442/404261442]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_kWvwyzftzL",
        "outputId": "b6437c10-27f6-4d30-cbec-c38f13609ab8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!unzip cased_L-12_H-768_A-12"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  cased_L-12_H-768_A-12.zip\n",
            "replace cased_L-12_H-768_A-12/bert_model.ckpt.meta? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: cased_L-12_H-768_A-12/bert_model.ckpt.meta  \n",
            "replace cased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: cased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001  y\n",
            "y\n",
            "\n",
            "replace cased_L-12_H-768_A-12/vocab.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename:   inflating: cased_L-12_H-768_A-12/vocab.txt  \n",
            "replace cased_L-12_H-768_A-12/bert_model.ckpt.index? [y]es, [n]o, [A]ll, [N]one, [r]ename:   inflating: cased_L-12_H-768_A-12/bert_model.ckpt.index  \n",
            "replace cased_L-12_H-768_A-12/bert_config.json? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: cased_L-12_H-768_A-12/bert_config.json  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0584oxlJf0yZ"
      },
      "source": [
        "!nohup bert-serving-start -model_dir=./cased_L-12_H-768_A-12 > out.file 2>&1 &max_seq_len=10"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNukmnkoliqm"
      },
      "source": [
        "## Get stated to run the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLIFnk3Qg37x",
        "outputId": "346bee29-c722-4156-ad13-e244a7291c46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python build_data.py\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO  \u001b[0mCreated new log directory models/bbn_modified_0.2_baseline_March25_sdd_[use_hierarchy = True, use_context_encoders = False, context_window = 10, mention_window = 10, attention_type = none, use_bilstm = False, use_marginal_ranking_loss = False]/bbn_modified_0.2_[all train, all test]/debug/log_25-03-2021_04:29:29.\n",
            "\u001b[36mDEBUG \u001b[0mDumped config to models/bbn_modified_0.2_baseline_March25_sdd_[use_hierarchy = True, use_context_encoders = False, context_window = 10, mention_window = 10, attention_type = none, use_bilstm = False, use_marginal_ranking_loss = False]/bbn_modified_0.2_[all train, all test]/debug/log_25-03-2021_04:29:29/config.txt.\n",
            "\u001b[36mDEBUG \u001b[0mDumped config to models/bbn_modified_0.2_baseline_March25_sdd_[use_hierarchy = True, use_context_encoders = False, context_window = 10, mention_window = 10, attention_type = none, use_bilstm = False, use_marginal_ranking_loss = False]/bbn_modified_0.2_[all train, all test]/debug/config.txt.\n",
            "\u001b[36mDEBUG \u001b[0mCONFIGDIR=%s\n",
            "\u001b[36mDEBUG \u001b[0m(private) matplotlib data path: %s\n",
            "\u001b[36mDEBUG \u001b[0mmatplotlib data path: %s\n",
            "\u001b[36mDEBUG \u001b[0mloaded rc file %s\n",
            "\u001b[36mDEBUG \u001b[0mmatplotlib version %s\n",
            "\u001b[36mDEBUG \u001b[0minteractive is %s\n",
            "\u001b[36mDEBUG \u001b[0mplatform is %s\n",
            "\u001b[36mDEBUG \u001b[0mloaded modules: %s\n",
            "\u001b[36mDEBUG \u001b[0mCACHEDIR=%s\n",
            "\u001b[36mDEBUG \u001b[0mUsing fontManager instance from %s\n",
            "\u001b[36mDEBUG \u001b[0mLoaded backend %s version %s.\n",
            "\u001b[36mDEBUG \u001b[0mLoaded backend %s version %s.\n",
            "2021-03-25 04:29:33.319576: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[36mDEBUG \u001b[0mFalling back to TensorFlow client; we recommended you install the Cloud TPU client directly with pip install cloud-tpu-client.\n",
            "\u001b[32mINFO  \u001b[0mBuilding category hierarchy.\n",
            "/ANIMAL                                  [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "/CONTACT_INFO                            [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "/CONTACT_INFO/ADDRESS                    [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "/CONTACT_INFO/PHONE                      [0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "/DISEASE                                 [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "/EVENT                                   [0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "/EVENT/HURRICANE                         [0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "/EVENT/WAR                               [0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "/FAC                                     [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "/FAC/AIRPORT                             [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "/FAC/BRIDGE                              [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "/FAC/BUILDING                            [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "/FAC/HIGHWAY_STREET                      [0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "/GAME                                    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "/GPE                                     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "/GPE/CITY                                [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "/GPE/COUNTRY                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "/GPE/STATE_PROVINCE                      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "/LANGUAGE                                [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "/LAW                                     [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "/LOCATION                                [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "/LOCATION/CONTINENT                      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "/LOCATION/LAKE_SEA_OCEAN                 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "/LOCATION/REGION                         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "/LOCATION/RIVER                          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "/ORGANIZATION                            [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "/ORGANIZATION/CORPORATION                [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0]\n",
            "/ORGANIZATION/EDUCATIONAL                [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0]\n",
            "/ORGANIZATION/GOVERNMENT                 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0]\n",
            "/ORGANIZATION/HOSPITAL                   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1]\n",
            "/ORGANIZATION/HOTEL                      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "/ORGANIZATION/POLITICAL                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "/ORGANIZATION/RELIGIOUS                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "/PERSON                                  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "/PLANT                                   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "/PRODUCT                                 [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "/PRODUCT/VEHICLE                         [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "/SUBSTANCE                               [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "/SUBSTANCE/CHEMICAL                      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "/SUBSTANCE/DRUG                          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "/SUBSTANCE/FOOD                          [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "/WORK_OF_ART                             [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "/WORK_OF_ART/BOOK                        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "/WORK_OF_ART/PLAY                        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "/WORK_OF_ART/SONG                        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\u001b[32mINFO  \u001b[0mHierarchy contains 45 categories total. [41 train, 34 test]\n",
            "\u001b[32mINFO  \u001b[0m4 categories are unique to the test dataset.\n",
            "\u001b[32mINFO  \u001b[0m30 categories are present in both train and test datasets.\n",
            "\u001b[32mINFO  \u001b[0mCategory hierarchy contains 45 categories.\n",
            "\u001b[32mINFO  \u001b[0mHierarchy contains 4 categories unique to the test set.\n",
            "\u001b[32mINFO  \u001b[0mLoading train dataset from data/datasets/bbn_modified_0.2/train.json.\n",
            "filepath and ds_name: data/datasets/bbn_modified_0.2/train.json train\n",
            "1029build_data.py:313: DeprecationWarning: The 'warn' function is deprecated, use 'warning' instead\n",
            "  logger.warn(\"%d of %d mentions in the %s dataset were trimmed due to exceeding the mention_window of %s after wordpiece tokenization.\" % (invalid_mentions_count, total_mentions, ds_name, cf.MODEL_OPTIONS['mention_window']))\n",
            "\u001b[33mWARNING \u001b[0m94 of 2238 mentions in the train dataset were trimmed due to exceeding the mention_window of 10 after wordpiece tokenization.\n",
            "\u001b[32mINFO  \u001b[0mBuilding data loader...\n",
            "\u001b[32mINFO  \u001b[0mThe train dataset was built successfully.\n",
            "\u001b[32mINFO  \u001b[0mDataset contains 223880 wordpieces (including overly long sentences).\n",
            "\u001b[32mINFO  \u001b[0mLoading dev dataset from data/datasets/bbn_modified_0.2/dev.json.\n",
            "filepath and ds_name: data/datasets/bbn_modified_0.2/dev.json dev\n",
            "644\u001b[33mWARNING \u001b[0m60 of 1420 mentions in the dev dataset were trimmed due to exceeding the mention_window of 10 after wordpiece tokenization.\n",
            "\u001b[32mINFO  \u001b[0mBuilding data loader...\n",
            "\u001b[32mINFO  \u001b[0mThe dev dataset was built successfully.\n",
            "\u001b[32mINFO  \u001b[0mDataset contains 142000 wordpieces (including overly long sentences).\n",
            "\u001b[32mINFO  \u001b[0mLoading test dataset from data/datasets/bbn_modified_0.2/test.json.\n",
            "filepath and ds_name: data/datasets/bbn_modified_0.2/test.json test\n",
            "644\u001b[33mWARNING \u001b[0m65 of 1340 mentions in the test dataset were trimmed due to exceeding the mention_window of 10 after wordpiece tokenization.\n",
            "\u001b[32mINFO  \u001b[0mBuilding data loader...\n",
            "\u001b[32mINFO  \u001b[0mThe test dataset was built successfully.\n",
            "\u001b[32mINFO  \u001b[0mDataset contains 134000 wordpieces (including overly long sentences).\n",
            "{'/PERSON': 457, '/ORGANIZATION/CORPORATION': 793, '/ORGANIZATION': 999, '/GPE': 515, '/GPE/COUNTRY': 213, '/PRODUCT': 41, '/PRODUCT/VEHICLE': 31, '/FAC': 23, '/FAC/BUILDING': 13, '/SUBSTANCE': 57, '/SUBSTANCE/FOOD': 16, '/ORGANIZATION/GOVERNMENT': 109, '/GPE/CITY': 224, '/ORGANIZATION/POLITICAL': 6, '/LOCATION/CONTINENT': 19, '/LOCATION': 49, '/GPE/STATE_PROVINCE': 66, '/FAC/HIGHWAY_STREET': 5, '/WORK_OF_ART/BOOK': 14, '/WORK_OF_ART': 39, '/LOCATION/LAKE_SEA_OCEAN': 4, '/WORK_OF_ART/SONG': 8, '/ANIMAL': 18, '/LOCATION/REGION': 23, '/LOCATION/RIVER': 1, '/GAME': 9, '/ORGANIZATION/EDUCATIONAL': 14, '/CONTACT_INFO/PHONE': 2, '/CONTACT_INFO': 3, '/LAW': 8, '/ORGANIZATION/HOTEL': 3, '/SUBSTANCE/DRUG': 10, '/EVENT': 16, '/EVENT/HURRICANE': 2, '/DISEASE': 3, '/SUBSTANCE/CHEMICAL': 14, '/FAC/AIRPORT': 1, '/ORGANIZATION/HOSPITAL': 1, '/LANGUAGE': 1, '/WORK_OF_ART/PLAY': 1, '/CONTACT_INFO/ADDRESS': 1}\n",
            "\u001b[32mINFO  \u001b[0mSaving data loaders to file...\n",
            "\u001b[32mINFO  \u001b[0mSaved data loaders to models/bbn_modified_0.2_baseline_March25_sdd_[use_hierarchy = True, use_context_encoders = False, context_window = 10, mention_window = 10, attention_type = none, use_bilstm = False, use_marginal_ranking_loss = False]/bbn_modified_0.2_[all train, all test]/asset/data_loaders.pkl.\n",
            "\u001b[32mINFO  \u001b[0mSaving vocabs and hierarchy to file...\n",
            "\u001b[32mINFO  \u001b[0mSaved word vocab to models/bbn_modified_0.2_baseline_March25_sdd_[use_hierarchy = True, use_context_encoders = False, context_window = 10, mention_window = 10, attention_type = none, use_bilstm = False, use_marginal_ranking_loss = False]/bbn_modified_0.2_[all train, all test]/asset/word_vocab.pkl.\n",
            "\u001b[32mINFO  \u001b[0mSaved wordpiece vocab to models/bbn_modified_0.2_baseline_March25_sdd_[use_hierarchy = True, use_context_encoders = False, context_window = 10, mention_window = 10, attention_type = none, use_bilstm = False, use_marginal_ranking_loss = False]/bbn_modified_0.2_[all train, all test]/asset/wordpiece_vocab.pkl.\n",
            "\u001b[32mINFO  \u001b[0mSaved hierarchy to models/bbn_modified_0.2_baseline_March25_sdd_[use_hierarchy = True, use_context_encoders = False, context_window = 10, mention_window = 10, attention_type = none, use_bilstm = False, use_marginal_ranking_loss = False]/bbn_modified_0.2_[all train, all test]/asset/hierarchy.pkl.\n",
            "\u001b[32mINFO  \u001b[0mSaved total_wordpieces to models/bbn_modified_0.2_baseline_March25_sdd_[use_hierarchy = True, use_context_encoders = False, context_window = 10, mention_window = 10, attention_type = none, use_bilstm = False, use_marginal_ranking_loss = False]/bbn_modified_0.2_[all train, all test]/asset/total_wordpieces.pkl.\n",
            "\u001b[36mDEBUG \u001b[0mSaved word vocab to models/bbn_modified_0.2_baseline_March25_sdd_[use_hierarchy = True, use_context_encoders = False, context_window = 10, mention_window = 10, attention_type = none, use_bilstm = False, use_marginal_ranking_loss = False]/bbn_modified_0.2_[all train, all test]/debug/word_vocab.txt.\n",
            "\u001b[36mDEBUG \u001b[0mSaved wordpiece vocab to models/bbn_modified_0.2_baseline_March25_sdd_[use_hierarchy = True, use_context_encoders = False, context_window = 10, mention_window = 10, attention_type = none, use_bilstm = False, use_marginal_ranking_loss = False]/bbn_modified_0.2_[all train, all test]/debug/wordpiece_vocab.txt.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kg2nFpQNeniQ"
      },
      "source": [
        "import sys\n",
        "import time\n",
        "from colorama import Fore, Back, Style"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnsvINplfFqg"
      },
      "source": [
        "!pip install cloud-tpu-client"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Au2I2PyFfWJI",
        "outputId": "5ee475e8-c291-486f-d712-8b283e52fefc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python3 train.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32mINFO  \u001b[0mCreated new log directory models/bbn_modified_0.2_baseline_March25_sdd_[use_hierarchy = True, use_context_encoders = False, context_window = 10, mention_window = 10, attention_type = none, use_bilstm = False, use_marginal_ranking_loss = False]/bbn_modified_0.2_[all train, all test]/debug/log_25-03-2021_04:30:30.\n",
            "\u001b[36mDEBUG \u001b[0mDumped config to models/bbn_modified_0.2_baseline_March25_sdd_[use_hierarchy = True, use_context_encoders = False, context_window = 10, mention_window = 10, attention_type = none, use_bilstm = False, use_marginal_ranking_loss = False]/bbn_modified_0.2_[all train, all test]/debug/log_25-03-2021_04:30:30/config.txt.\n",
            "\u001b[36mDEBUG \u001b[0mDumped config to models/bbn_modified_0.2_baseline_March25_sdd_[use_hierarchy = True, use_context_encoders = False, context_window = 10, mention_window = 10, attention_type = none, use_bilstm = False, use_marginal_ranking_loss = False]/bbn_modified_0.2_[all train, all test]/debug/config.txt.\n",
            "\u001b[36mDEBUG \u001b[0mCONFIGDIR=%s\n",
            "\u001b[36mDEBUG \u001b[0m(private) matplotlib data path: %s\n",
            "\u001b[36mDEBUG \u001b[0mmatplotlib data path: %s\n",
            "\u001b[36mDEBUG \u001b[0mloaded rc file %s\n",
            "\u001b[36mDEBUG \u001b[0mmatplotlib version %s\n",
            "\u001b[36mDEBUG \u001b[0minteractive is %s\n",
            "\u001b[36mDEBUG \u001b[0mplatform is %s\n",
            "\u001b[36mDEBUG \u001b[0mloaded modules: %s\n",
            "\u001b[36mDEBUG \u001b[0mCACHEDIR=%s\n",
            "\u001b[36mDEBUG \u001b[0mUsing fontManager instance from %s\n",
            "\u001b[36mDEBUG \u001b[0mLoaded backend %s version %s.\n",
            "\u001b[36mDEBUG \u001b[0mLoaded backend %s version %s.\n",
            "2021-03-25 04:30:32.256547: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "\u001b[32mINFO  \u001b[0mLoading files...\n",
            "\u001b[32mINFO  \u001b[0mLoaded data loaders from models/bbn_modified_0.2_baseline_March25_sdd_[use_hierarchy = True, use_context_encoders = False, context_window = 10, mention_window = 10, attention_type = none, use_bilstm = False, use_marginal_ranking_loss = False]/bbn_modified_0.2_[all train, all test]/asset/data_loaders.pkl.\n",
            "\u001b[32mINFO  \u001b[0mLoaded word vocab from models/bbn_modified_0.2_baseline_March25_sdd_[use_hierarchy = True, use_context_encoders = False, context_window = 10, mention_window = 10, attention_type = none, use_bilstm = False, use_marginal_ranking_loss = False]/bbn_modified_0.2_[all train, all test]/asset/word_vocab.pkl.\n",
            "\u001b[32mINFO  \u001b[0mLoaded wordpiece vocab from models/bbn_modified_0.2_baseline_March25_sdd_[use_hierarchy = True, use_context_encoders = False, context_window = 10, mention_window = 10, attention_type = none, use_bilstm = False, use_marginal_ranking_loss = False]/bbn_modified_0.2_[all train, all test]/asset/wordpiece_vocab.pkl.\n",
            "\u001b[32mINFO  \u001b[0mLoaded total wordpieces from models/bbn_modified_0.2_baseline_March25_sdd_[use_hierarchy = True, use_context_encoders = False, context_window = 10, mention_window = 10, attention_type = none, use_bilstm = False, use_marginal_ranking_loss = False]/bbn_modified_0.2_[all train, all test]/asset/total_wordpieces.pkl.\n",
            "\u001b[32mINFO  \u001b[0mLoaded hierarchy from models/bbn_modified_0.2_baseline_March25_sdd_[use_hierarchy = True, use_context_encoders = False, context_window = 10, mention_window = 10, attention_type = none, use_bilstm = False, use_marginal_ranking_loss = False]/bbn_modified_0.2_[all train, all test]/asset/hierarchy.pkl.\n",
            "\u001b[32mINFO  \u001b[0mBuilding model.\n",
            "\u001b[32mINFO  \u001b[0mTraining model.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}